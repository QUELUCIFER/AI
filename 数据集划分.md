## Teain-Test-Split

        from sklearn.model_selection import train_test_split
        X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2)


## Cross-Validation

K-Folds Cross Validation

在K-Folds交叉验证中，我们将数据分割成k个不同的子集。我们使用第k-1个子集来训练数据，并留下最后一个子集作为测试数据。然后，我们对每个子集模型计算平均值，接下来结束模型。之后，我们对测试集进行测试。
  
        from sklearn.model_selection import KFold
        KFold(n_splits=2, random_state=None, shuffle=False)

弃一法交叉验证（Leave One Out Cross Validation，LOOCV)

        from sklearn.model_selectionimportLeaveOneOut
        loo = LeaveOneOut()
        loo.get_n_splits(X)

在大数据集中，通常建议k＝3。在更小的数据集中，正如我之前提到的，最好使用弃一法交叉验证。

        from sklearn.cross_validation import cross_val_score, cross_val_predict
        from sklearn import metrics
        scores = cross_val_score(model, df, y, cv=6)
        predictions = cross_val_predict(model, df, y, cv=6)
        plt.scatter(y, predictions)
        accuracy = metrics.r2_score(y, predictions)


