
机器学习越来越多地从人工设计模型转向使用 H20、TPOT 和 auto-sklearn 等工具自动优化的工具。这些库以及随机搜索（参见《Random Search for Hyper-Parameter Optimization》）等方法旨在通过寻找匹配数据集的最优模型来简化模型选择和机器学习调优过程，而几乎不需要任何人工干预。然而，特征工程作为机器学习流程中可能最有价值的一个方面，几乎完全是人工的。

特征工程也被称为特征构造，是从现有数据中构造新的特征从而训练机器学习模型的过程。这一步可能比实际上使用的模型更重要，因为一个机器学习算法只能从我们给定的数据中学习，所以构造一个和任务相关的特征是至关重要的，参见优质论文《A Few Useful Things to Know about Machine Learning》。


[feature-tools](https://docs.featuretools.com/)  [github-fr](https://github.com/WillKoehrsen/automated-feature-engineering/blob/master/walk_through/Automated_Feature_Engineering.ipynb)

[Feature Tools：可自动构造机器学习特征的Python库](https://www.jiqizhixin.com/articles/2018-06-21-2)

### feature-scaling

1.rescaling![ ](https://pic3.zhimg.com/80/v2-1874c0fd4801124ad29d6b2ff5d78d56_hd.jpg)


2.Mean normalization![ ](https://pic4.zhimg.com/80/v2-1232fae014a02e150ed2b78e463a16ce_hd.jpg)


3.Standardization![ ](https://pic2.zhimg.com/80/v2-9734f7841b544443b591bfbf54a7f041_hd.jpg)



4.Scaling to unit length![ ](https://pic2.zhimg.com/80/v2-ca8f8c4e0c60572bc2f0ecce563f006e_hd.jpg)

### dictvectorizer

[Python机器学习中的DictVectorizer（特征向量化）的使用说明](https://blog.csdn.net/Jon_Sheng/article/details/79693971)


特征转换

最近在看《PYTHON机器学习及实践+从零开始通往KAGGLE竞赛之路》这本书，

书中采用最简单直接的方式介绍了机器学习的入门实践语句，简单介绍原理以后，就开始代码实现了。

刚好看到一个例子，关于DictVectorizer的使用，很是喜欢这种操作方式，代码如下：

        from sklearn.feature_extraction import DictVectorizer
 
        dict_vec = DictVectorizer(sparse=False)# #sparse=False意思是不产生稀疏矩阵
 
        X_train = dict_vec.fit_transform(X_train.to_dict(orient='record'))
        X_test = dict_vec.transform(X_test.to_dict(orient='record'))
        print(dict_vec.feature_names_)#查看转换后的列名
        print(X_train)#查看转换后的训练集

['age','pclass=1st', 'pclass=2nd', 'pclass=3rd', 'sex=female', 'sex=male']
[[31.19418104  0.          0.          1.          0.          1.        ]
 [31.19418104  1.          0.          0.          1.          0.        ]
 [31.19418104  0.          0.          1.          0.          1.        ]
 ...
 [12.          0.          1.          0.          1.          0.        ]
 [18.          0.          1.          0.          0.          1.        ]
 [31.19418104  0.          0.          1.          1.          0.        ]]
原pclass和sex列如下：

full[['Pclass','Sex']].head()
	Pclass	Sex
0	3	male
1	1	female
2	3	female
3	1	female
4	3	male
即pclass和sex两列分类变量转换为了数值型变量（只有0和1），age列数值型保持不变，达到了机器学习的识别目的。



该方法可用pandas中的get_dummies实现（同样可以实现one-hot编码），操作会复杂一些，代码如下：

        Pclassdf = pd.DataFrame()
        Pclassdf = pd.get_dummies(full['Pclass'],prefix='Pclass')
        Pclassdf.head()

Pclass_1	Pclass_2	Pclass_3
0	0	0	1
1	1	0	0
2	0	0	1
3	1	0	0
4	0	0	1

有多少特征，就会新创建多少列，在之后用pd.concat连接即可，并且需要把原Pclass给drop掉。

