1.[Keras 模型中使用预训练的 gensim 词向量和可视化](https://eliyar.biz/using-pre-trained-gensim-word2vector-in-a-keras-model-and-visualizing/)

2.[Transformer原理和实现 从入门到精通](https://state-of-art.top/2019/01/17/Transformer%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0-%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/)

3.[放弃幻想，全面拥抱Transformer：自然语言处理三大特征抽取器（CNN/RNN/TF）比较](https://zhuanlan.zhihu.com/p/54743941)

4.[word2vec 模型的详细数学推导和直观理解](https://blog.csdn.net/hsiffish/article/details/78673924)

5.[word2vec 中的数学原理详解（一）目录和前言](https://blog.csdn.net/itplus/article/details/37969519)

6.[受限玻尔兹曼机（RBM）学习笔记（一）预备知识](https://blog.csdn.net/itplus/article/details/19168937)

7.[DeepNLP的表示学习·词嵌入来龙去脉·深度学习（Deep Learning）·自然语言处理（NLP）·表示（Representation）](https://blog.csdn.net/scotfield_msn/article/details/69075227)

